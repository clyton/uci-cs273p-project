{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32560, 14)\n",
      "(32560, 1)\n"
     ]
    }
   ],
   "source": [
    "%run pipeline_utils.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "# votingP = joblib.load('voting_model.pkl') # using tuned models assigned heuristic weights\n",
    "xgbP = joblib.load('xgb_grid_model.pkl') # tuned using grid search\n",
    "rfcP = joblib.load('rfc_grid_model.pkl') # tuned using randomized search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explicitly run voting pipeline. That model was not picklable because of some function transformer used in pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run voting_pipeline.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ygb = xgbP.predict(Xva)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yrf = rfcP.predict(Xva)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = Ygb != Yrf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True, False, False, False, False,  True, False, False,\n",
       "       False])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RF misclassifies a data point as 0 while XGB classifies it as 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We observe that the second sample Xts.iloc[1] is getting misclassified by one of the classifier\n",
    "# In the below case Xts[1] should be classified as 1 but RF mis-classifies it as 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                                32\n",
       "workclass                     Private\n",
       "fnlwgt                         185027\n",
       "education                  Assoc-acdm\n",
       "education-num                      12\n",
       "marital-status     Married-civ-spouse\n",
       "occupation               Craft-repair\n",
       "relationship                  Husband\n",
       "race                            White\n",
       "sex                              Male\n",
       "capital-gain                        0\n",
       "capital-loss                     1887\n",
       "hours-per-week                     40\n",
       "native-country                Ireland\n",
       "Name: 11931, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xva.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Yva[1] # the actual class is 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ygb[1] # XGB predicts correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Yrf[1] # RF predicts wrongly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.60641334, 0.39358666])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets observe the confidence score for this classification\n",
    "Yrf_conf = rfcP.predict_proba(Xva)\n",
    "Yrf_conf[1] # RF is confused between the two classes: 60% vs 39%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.1217519, 0.8782481], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ygb_conf = xgbP.predict_proba(Xva)\n",
    "Ygb_conf[1] # XGB on  the other hand is very sure about its prediction : 87%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observation\n",
    "So we can see that though random forest chose class 0, it chose with confidence of 60% while XgBoost classified the same point as class-1 with confidence 87%. If we had a voting mechanism in which we weighed low those predictions which have small confidence and weighed high those predictions which are sure we could improve the classification accuracy. This can be an area of future exploration.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGB misclassifies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind = np.logical_and((Yva.ravel()!=Ygb.ravel()),(Yva.ravel()==Yrf.ravel()))\n",
    "ind[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                                40\n",
       "workclass                     Private\n",
       "fnlwgt                         136244\n",
       "education                Some-college\n",
       "education-num                      10\n",
       "marital-status     Married-civ-spouse\n",
       "occupation               Adm-clerical\n",
       "relationship                     Wife\n",
       "race                            White\n",
       "sex                            Female\n",
       "capital-gain                        0\n",
       "capital-loss                        0\n",
       "hours-per-week                     40\n",
       "native-country          United-States\n",
       "Name: 7933, dtype: object"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xva.iloc[-2] # the data that got miclassified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Yva[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ygb[-2] # xgb got it wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Yrf[-2] # RF got it right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.48785216, 0.51214784], dtype=float32)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So let's analyze their confidence level for this prediction\n",
    "Ygb_conf[-2] # here we observe that XGB is totally confused about this data point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.73363899, 0.26636101])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Yrf_conf[-2] # here we observe that YRF on the other hand has a decent confidence on its prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We try to improve this by adding a voting classifier to our models, but we did not implement dynamic weights \n",
    "predictions based on their confidence level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
